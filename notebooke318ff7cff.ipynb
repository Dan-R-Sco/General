{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Imbalance treatment**\n\nUsing creditcard dataset held on Kaggle kernel. Showing the use of Oversampling Synthetic data (SMOTE) against Undersampling the majority class (NearMiss)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas  as pd \nimport matplotlib.pyplot as plt \nimport numpy as np \nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score \n  \n# load the data set \ndata = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv') \n  \n# print info about columns in the dataframe \nprint(data.info()) ","execution_count":1,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.columns)","execution_count":2,"outputs":[{"output_type":"stream","text":"Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n       'Class'],\n      dtype='object')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalise the amount column \ndata['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1, 1)) \n\n# drop Time and Amount columns as they are not relevant for prediction purpose \ndata = data.drop(['Time', 'Amount'], axis = 1) \n\n# as you can see there are 492 fraud transactions. \ndata['Class'].value_counts() ","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"0    284315\n1       492\nName: Class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n# visualize the target variable\ng = sns.countplot(data['Class'])\ng.set_xticklabels(['Not Fraud','Fraud'])\nplt.show()","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class', 'normAmount'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28','normAmount']]\ny = data['Class']","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Without any balancing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \n\n# split into 70:30 ration \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) \n\n# describes info about train and test set \nprint(\"Number transactions X_train dataset: \", X_train.shape) \nprint(\"Number transactions y_train dataset: \", y_train.shape) \nprint(\"Number transactions X_test dataset: \", X_test.shape) \nprint(\"Number transactions y_test dataset: \", y_test.shape) ","execution_count":18,"outputs":[{"output_type":"stream","text":"Number transactions X_train dataset:  (199364, 29)\nNumber transactions y_train dataset:  (199364,)\nNumber transactions X_test dataset:  (85443, 29)\nNumber transactions y_test dataset:  (85443,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Metrics\n## Recall is the number of frauds model found correctly over the number of fraud in the whole dataset\n## Precision is the number of frauds found correctly over the number of frauds model found "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train model without handling imbalanced class distribution\n\n# logistic regression object \nlr = LogisticRegression() \n  \n# train the model on train set \nlr.fit(X_train, y_train.ravel()) \n  \npredictions = lr.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions)) \nprint(roc_auc_score(y_test, predictions))","execution_count":22,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85296\n           1       0.88      0.62      0.73       147\n\n    accuracy                           1.00     85443\n   macro avg       0.94      0.81      0.86     85443\nweighted avg       1.00      1.00      1.00     85443\n\n0.8094534662486266\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"accuracy of 100% but the minority class has 62% recall.  Low recall indicates a high number of false negatives"},{"metadata":{},"cell_type":"markdown","source":"# **Random undersampling**"},{"metadata":{},"cell_type":"markdown","source":"Undersampling can be defined as removing some observations of the majority class. This is done until the majority and minority class is balanced out. RandomUnderSampler is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. Under-sample the majority class(es) by randomly picking samples with or without replacement"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import library\nfrom imblearn.under_sampling import RandomUnderSampler\n\nprint(\"Before Random Undersampling, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before Random Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n\nrus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\nX_rus, y_rus = rus.fit_resample(X, y)\n\nprint('After Random Undersampling, counts of label 1:', (y_rus.shape))\nprint('After Random Undersampling, counts of label 0:', (X_rus.shape))","execution_count":9,"outputs":[{"output_type":"stream","text":"Before Random Undersampling, counts of label '1': 345\nBefore Random Undersampling, counts of label '0': 199019 \n\nAfter Random Undersampling, counts of label 1: (984,)\nAfter Random Undersampling, counts of label 0: (984, 29)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model on train set \nlr3 = LogisticRegression() \nlr3.fit(X_rus, y_rus.ravel()) \npredictions = lr3.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions)) \nprint(roc_auc_score(y_test, predictions))\n","execution_count":10,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98     85296\n           1       0.04      0.93      0.08       147\n\n    accuracy                           0.96     85443\n   macro avg       0.52      0.94      0.53     85443\nweighted avg       1.00      0.96      0.98     85443\n\n0.9449757674594881\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- Low precision indicates a high number of false positives."},{"metadata":{},"cell_type":"markdown","source":"# Random Oversampling"},{"metadata":{},"cell_type":"markdown","source":"Generate new samples in the minority classes. The most naive strategy is to generate new samples by randomly sampling with replacement of the currently available samples. Oversampling can be defined as adding more copies to the minority class. Oversampling can be a good choice when you donâ€™t have a ton of data to work with.\n\n -Can cause overfitting and poor generalization to test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import library\nfrom imblearn.over_sampling import RandomOverSampler\n\nprint(\"Before Random Oversampling, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before Random Oversampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n\nros = RandomOverSampler(random_state=42)\n\n# fit predictor and target varaible\nX_ros, y_ros = ros.fit_resample(X, y)\n\nprint('Resample dataset shape label 1', (y_ros.shape))\nprint('Resample dataset shape label 0', (X_ros.shape))","execution_count":11,"outputs":[{"output_type":"stream","text":"Before Random Oversampling, counts of label '1': 345\nBefore Random Oversampling, counts of label '0': 199019 \n\nResample dataset shape label 1 (568630,)\nResample dataset shape label 0 (568630, 29)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model on train set \nlr4 = LogisticRegression() \nlr4.fit(X_ros, y_ros.ravel()) \npredictions = lr4.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions)) \nprint(roc_auc_score(y_test, predictions))\n","execution_count":12,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99     85296\n           1       0.07      0.92      0.12       147\n\n    accuracy                           0.98     85443\n   macro avg       0.53      0.95      0.56     85443\nweighted avg       1.00      0.98      0.99     85443\n\n0.9479111636213292\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- Low precision indicates a high number of false positives."},{"metadata":{},"cell_type":"markdown","source":"# **NearMiss Algorithm**\n\nUndersampled the majority instances and made it equal to majority class. The same number of majority as minority"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Before Near miss, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before Near miss, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n  \n# apply near miss \nfrom imblearn.under_sampling import NearMiss \nnr = NearMiss() \n  \nX_train_miss, y_train_miss = nr.fit_sample(X_train, y_train.ravel()) \n  \nprint('After Near miss, the shape of train_X: {}'.format(X_train_miss.shape)) \nprint('After Near miss, the shape of train_y: {} \\n'.format(y_train_miss.shape)) \n  \nprint(\"After Near miss, counts of label '1': {}\".format(sum(y_train_miss == 1))) \nprint(\"After Near miss, counts of label '0': {}\".format(sum(y_train_miss == 0))) \n","execution_count":13,"outputs":[{"output_type":"stream","text":"Before Near miss, counts of label '1': 345\nBefore Near miss, counts of label '0': 199019 \n\nAfter Near miss, the shape of train_X: (690, 29)\nAfter Near miss, the shape of train_y: (690,) \n\nAfter Near miss, counts of label '1': 345\nAfter Near miss, counts of label '0': 345\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model on train set \nlr2 = LogisticRegression() \nlr2.fit(X_train_miss, y_train_miss.ravel()) \npredictions = lr2.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions)) \nprint(roc_auc_score(y_test, predictions))\n","execution_count":14,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.55      0.71     85296\n           1       0.00      0.95      0.01       147\n\n    accuracy                           0.56     85443\n   macro avg       0.50      0.75      0.36     85443\nweighted avg       1.00      0.56      0.71     85443\n\n0.7534836669614384\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- Low precision indicates a high number of false positives."},{"metadata":{},"cell_type":"markdown","source":"> "},{"metadata":{},"cell_type":"markdown","source":"# **SMOTE**\n\nOversampling of the minority with synthetic data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before SMOTE, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before SMOTE, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n  \n# import SMOTE module from imblearn library \n# pip install imblearn (if you don't have imblearn in your system) \nfrom imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 2) #k_neighbors (default=5)\n\nX_smote_train, y_smote_train = sm.fit_sample(X_train, y_train.ravel()) \n  \nprint('After SMOTE, the shape of train_X: {}'.format(X_smote_train.shape)) \nprint('After SMOTE, the shape of train_y: {} \\n'.format(y_smote_train.shape)) \n  \nprint(\"After SMOTE, counts of label '1': {}\".format(sum(y_smote_train == 1))) \nprint(\"After SMOTE, counts of label '0': {}\".format(sum(y_smote_train == 0))) \n","execution_count":15,"outputs":[{"output_type":"stream","text":"Before SMOTE, counts of label '1': 345\nBefore SMOTE, counts of label '0': 199019 \n\nAfter SMOTE, the shape of train_X: (398038, 29)\nAfter SMOTE, the shape of train_y: (398038,) \n\nAfter SMOTE, counts of label '1': 199019\nAfter SMOTE, counts of label '0': 199019\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr1 = LogisticRegression() \nlr1.fit(X_smote_train, y_smote_train.ravel()) \npredictions = lr1.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions)) \nprint(roc_auc_score(y_test, predictions))\n","execution_count":16,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99     85296\n           1       0.06      0.92      0.11       147\n\n    accuracy                           0.98     85443\n   macro avg       0.53      0.95      0.55     85443\nweighted avg       1.00      0.98      0.99     85443\n\n0.9468618764331843\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- Low precision indicates a high number of false positives"},{"metadata":{},"cell_type":"markdown","source":"# **Tomek links**\n\nTomek links are pairs of very close instances of opposite classes. Removing these instances, increases the margin of the classification. \n\nTomek links exist if two samples are the nearest neighbours of each **other"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load library\nfrom imblearn.under_sampling import TomekLinks\n\nprint(\"Before Random Oversampling, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before Random Oversampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n\ntl = TomekLinks(sampling_strategy='majority')\n\n# fit predictor and target variable\nX_tl, y_tl = tl.fit_sample(X, y)\n\nprint('Resample dataset shape label 1 ', (y_tl.shape))\nprint('Resample dataset shape label 0 ', (X_tl.shape))","execution_count":17,"outputs":[{"output_type":"stream","text":"Before Random Oversampling, counts of label '1': 345\nBefore Random Oversampling, counts of label '0': 199019 \n\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-66f54b35695f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# fit predictor and target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_tl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resample dataset shape label 1 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_tl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_tomek_links.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tomek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 delayed_query(\n\u001b[1;32m    664\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 665\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             )\n\u001b[1;32m    667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model on train set \nlr5 = LogisticRegression() \nlr5.fit(X_tl, y_tl.ravel()) \npredictions = lr5.predict(X_test) \n  \n# print classification report \nprint(classification_report(y_test, predictions)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**note the higher precision but lower recall**"},{"metadata":{},"cell_type":"markdown","source":"# **Use Penalize Algorithms**\n\nThis can increase the cost of classification mistake on minority class. For svm, use 'class_weight = 'balanced'"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n# we can add class_weight='balanced' to add panalize mistake\nsvc_model = SVC(class_weight='balanced', probability=True)\n\nsvc_model.fit(X_train, y_train)\n\nsvc_predict = svc_model.predict(X_test)\n\nprint(classification_report(y_test, svc_predict)) \nprint(roc_auc_score(y_test, svc_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Tree based**"},{"metadata":{},"cell_type":"markdown","source":"Decision trees frequently perform well on imbalanced data. In modern machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load library\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\n# fit the predictor and target\nrfc.fit(X_train, y_train)\n\n# predict\nrfc_predict = rfc.predict(X_test)\n\nprint(classification_report(y_test, rfc_predict)) \nprint(roc_auc_score(y_test, rfc_predict))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}